---
title:  "CS224n_Lecture1"
date: 2017-08-03 00:00:00
comments: true
---

- CS224n Lecture1에 대한 내용을 정리하였다.

1강에선 주로 개략적으로 NLP에 대해 소개하는 위주로 설명하는 내용을 다루고 있다.
NLP는 무엇인가? 컴퓨터 과학, AI, 언어학 세가지가 모여서 만든 분야라고 정의하고 있다.
이 분야의 목적은 computer가 특정 일을 수행하기 위해 자연어를 이해하는 것을 목표로 삼고 있다.
예를 들면 Siri, Cortana, Alexa 등을 통해 약속을 잡고 물건을 사는 일 등의 것들을 말한다.

NLP의 분야는 세분화되어 아래와 같은 구조로 나타낼 수 있다. CS224n 수업에서는 Speech, Synthatic analysis,
Semantic Interpretation을 위주로 가르칠 예정이다.
![NLP Levels](https://whikwon.github.io/images/Lecture1_NLP_Levels.PNG)
<CS224n Lecture1 slide_4>

NLP의 현재의 사용되는 예시 몇 가지를 들어보면 스펠링 교정, 키워드 찾기, 동의어 찾기/웹사이트에서 원하는 제품, 사람, 회사 등의 정보 가져오기
/문서에 대한 감정 분석/기계 번역/spoken dialog system/복잡한 질문 묻고 답하기 등이 있겠다.

그리고 앞으로 이런 연구들이 더 활발해져서 Search/온라인 광고 매칭/자동 번역/감정 분석/음성 인식/챗봇/Dialog agent 등의 분야에서
많은 발전이 일어날 것이다.

그럼 인간의 언어가 왜 그렇게 특별할까? <br>
바로 speaker/writer의 의미에 따라 새롭게 설계되어서 전달되기 때문이다.
인간의 언어는 discrete/symbolic/categorial의 세가지 signaling system으로 이루어지며
어떻게 표현되냐에 따라서 조금씩 다른 의미를 갖게 된다.

그리고 categoriacal symbol이 소리, 제스처, 이미지 등으로 encoding될 수 있기 때문에
이렇게 다양한 방법으로 encoding된 의미가 전달되어 이에 대한 pattern을 알기 어렵다. (sparsity)
이런 점 때문에 기계가 학습하는데 어려움이 존재한다.

딥러닝에 대한 설명은 생략하도록 하겠다.
처음으로 NLP에서 성공을 거둔 분야는 음성 인식으로, Hinton 교수가 2010년의 논문에서 과거 방식 대비 월등한 성능을
내어 화제가 되었다고 한다.

Deep NLP는 최근에 큰 성과를 많은 분야에서 이루었다고 한다.
한번 쯤 보면 좋을 듯해서 정리한다. <br>

***
[Deep NLP 관련 분야] <br>
- Levels : speech, words, syntax, semantics
- Tools : parts-of-speech, entities, parsing
- Applications : machine translation, setiment analysis, dialogure agents, question answering

***
딥러닝에서 모든 단어를 vector로 만든 뒤에 이를 조합해서 논리적인 표현을 하는데에 사용한다.
뒤에 Sentimental analysis와 Question answering에 대한 예제가 나오는데 모두 morphology, syntax, logical semantics & sentiment
에 사용된 모델을 다시 사용했다고 한다. generalization이 된다는 얘긴거 같다.

1강에선 NLP에 대한 소개만 진행하여 전반적으로 왜 학습이 어려운지, 딥러닝이 왜 못 해결하던 문제들을
해결할 수 있게 했는지 정도만 생각하면 될 듯하다. <br>


Reference: <br>
[Stanford CS224n lecture1 slides](http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture1.pdf)
