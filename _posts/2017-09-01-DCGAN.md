---
title: DCGAN
date: 2017-09-02 00:00:00
comments: true
---

- GAN에 CNN을 접목시켜 좋은 성능을 낸 DCGAN에 대한 논문을 정리했다.

### Introduction

unlabeled dataset에서 reusable feature를 학습하는 게 조명 받고 많은 연구가 진행 중이다. <br>
이 논문에선 그 중 GAN에 대해서 다룰 예정이다. 이 때까지만 해도 다양한 구조가 나오지 않았기 때문에
GAN에 대한 이해가 부족해서 CNN을 접목시키고, 시각화를 통해서 내부 구조를 파헤치는 내용을 위주로 전개한다.
다룰 내용들은 아래와 같다.

1. Train이 잘 되는 Convolutional GAN 구조를 만들어서 이를 DCGAN이라고 부른다. <br>
2. 생성된 샘플을 이미 trained된 discriminator를 사용해서 분류한 뒤 다른 unsupervised 모델의 성능과 비교한다.<br>
3. 학습된 GAN의 filter를 시각화해서 empirical하게 어떤 filter가 어떤 물체를 그리기 위해 학습되었는지 본다. <br>
4. Generator을 통해 생성된 샘플들을 조작해서 vector arithmetic property가 있는 것을 확인한다. <br>

그리고 추가적으로 **GAN의 문제점 중 하나인 memorization 특성이 DCGAN에서 일어나는 지에 대해서도 예제를 통해 살펴본다.**

### Related Work

Generative image model은 크게 parametric, non-parametric으로 나누어진다.
non-parametric 방법은 image 매칭, texture synthesis, super-resolution, in-paining 등에 사용되어 왔다.

그에 반면에 parametric은 2000년대에 MNIST 데이터를 잠깐 다룬 것을 제외하고 실제 세계의 natural image를
generate하는 쪽으로 큰 발전이 없었다고 한다.

그러다 VAE, GAN이 등장했고 VAE는 약간 blurry하다는 단점, GAN은 noisy, incomprehensible하다는 단점이 존재하나
계속해서 연구가 진행되고 있는 분야이다.

neural network가 black-box method라는 점을 언급하고 최근에 filter의 역할을 알기 위한 guided backpropagation을
사용한 [논문](https://arxiv.org/abs/1311.2901)을 언급하고 있다. 앞서 소개했듯이 해당 논문에서 이들 내용을 바탕으로 filter들의 역할에 대한 이해를 중점적으로 다룰 예정이다.

### Approache and Model architecture

초창기에 GAN에 CNN을 사용하려는 시도가 있었으나 별로 성공하지 못했고 저자는 많은 다양한 시도를 한 끝에(***노가다?***)
stable하게 training이 되는 모델을 만들었다고 언급하고 있다.

모델 구조에 대해 상세하게 설명하고 있으며 이를 정리해놓은 내용은 아래와 같다.

1. 모든 convolutional net에서 deterministic spatial pooling(max pooling)을 **strided convolution** 으로 대체한다.
그래서 discriminator에서는 spatial downsampling을, generator에는 spatial upsampling을 학습하도록 한다.
(*maxpooling의 어떤 성질 때문에 그런거지? 약간 이해가 안 된다.*)
2. convolutional feature 마지막 layer에서 **fully connected layer를 제거한다.** (*요즘 트렌드*)
대신 **global average pooling** 을 사용할 수 있다. 그리고 논문에서는 generator의 output을 discriminator에 직접
전달하는 방식을 취해서 좋은 결과를 얻었다고 한다. generator의 첫번째 layer가 FC layer라고 볼 수도 있는데 결과로 4-D tensor를
얻으므로 신경쓰지 않아도 되고 discriminator는 마지막 convolution 마지막 layer가 flatten되어 sigmoid output에 넣어진다.
3. **Batch normalization** 을 사용해서 initialization 문제와 gradient flow를 개선해줬다. 그리고 generate된 샘플이 한 point
에 집중되는 문제를 어느 정도 완화시켜준다고 한다. 그리고 모든 layer에 적용하면 sample oscillation, model instability가
발생해서 generator output, discriminator input layer에는 적용시키지 않는다.
4. generator에서는 output 제외하고 **ReLu** 를, discriminator에서는 전부 **LeakyReLU** 를 사용한다. Bounded activation을 사용하는게
모델이 training distribution의 color space를 커버하고 빨리 saturate시킨다고 한다.

위에서 설명한 generator는 아래 구조의 그림으로 표현 가능하다.
![structure](https://whikwon.github.io/images/dcgan_structure.png)

### Details of Adversarial training

LSUN(침실 사진), Imagenet-1k, 새롭게 만든 FACES(사람 얼굴) 세 가지 데이터에 대해 학습시켰고 방법은 아래와 같다.

1. tanh activation의 범위인 [-1, 1]로 image를 scaling하고 다른 전처리는 하지 않는다.
2. mini-batch SGD로, batch_size는 128로 training 시킨다.
3. weights는 mean 0, std 0.02 인 정규분포로 initialization 한다.
4. leaky ReLU의 leak slope은 0.2로 설정한다.
5. 기존 GAN의 momentum에서 Adam optimzer로 변경해준다.
6. learning_rate는 0.001에서 0.0002로 낮춘다.
7. momentum term $$\beta_1$$가 0.9일 때 oscillation, instability를 야기해서 0.5로 낮추니 training에 도움이 되었다.

#### LSUN

LSUN 데이터를 통해 확인하려는 점은 첫번째로 기존에 고해상도 image에 대해서 생성이 거의 불가능했었는데
DCGAN을 통해 학습할 수 있는지, 두번째는 이렇게 학습해서 생성한 샘플들이 memorization에 의한 것은 아닌지
에 대한 확인이다.
LSUN을 학습시킬 때는 memorization 문제를 피하기 위해서 deduplication이라는 테크닉을 사용한다고
논문에서 소개하고 있는데 일단 그렇다는 점만 알고 넘어가도록 하겠다.  

아래는 LSUN 데이터로 epoch 1회 학습시킨 후에 생성한 샘플이다. <br>
![lsun1](https://whikwon.github.io/images/dcgan_lsun1.png) <br>
memorization이 발생하는 지 확인하기 위해서 1회만 학습시켰는데 샘플을 어느 정도 잘 학습하는 것으로 보인다. <br>
조금 더 학습을 시켰을 때 이미지는 아래와 같다. <br>
![lsun2](https://whikwon.github.io/images/dcgan_lsun2.png) <br>
마찬가지로 샘플의 질이 상당히 좋음을 알 수 있고 논문에서는 침대 머리 부분에 noise texture가 반복되는 걸로 보아
아직까진 underfitting이 일어난다고 얘기하고 있다.
추가적으로 vector arithmetic property는 뒷 장에서 확인한다.

### Empirical validation of DCGAN's capabilities

DCGAN의 성능을 평가하기 위해서 이를 feature extractor로 사용해서 얻은 feature로 supervised 데이터셋에 대한 평가를
진행하는 방법이 있다. CIFAR10을 데이터셋으로 하여 K-means, Exemplar CNN의 모델들과 비교를 하였고 유사한 성능을 내는 것으로
확인되었다. SVHN 데이터셋을 이용해서도 평가를 진행하는데 여기에선 CNN 구조보다 더 성능이 좋게 나왔다고 한다.


### Investigating and Visualizing the internals of the networks

generator, discriminator의 내부 구조를 확인하기 위해서 기존의 nearest neighbor나 log-likelihood metric은
안 좋아 사용하지 않는다고 한다. 몇 가지 방법을 제시하는데 아래에서 각각 살펴보도록 하자.

#### 1) Walking in the latent space

latent space($$z$$)의 manifold를 따라 걷다보면 memorization이 발생했는지 확인할 수 있다고 한다.
특정한 점에서 이미지를 memorize하고 있을 경우에 갑자기 sharp한 transition이 발생할 것이기 때문이다.
그리고 $$z$$값이 이동할 때 이미지가 semantic한 변화를 보인다고 하면(*특정 물체가 사라지거나 생기거나*)
관련된 흥미로운 representation을 배울 수 있다고 한다. <br>
![lsun3](https://whikwon.github.io/images/dcgan_lsun3.png) <br>
latent space에서 random하게 10개 point를 뽑아서 interpolation을 했을 때 위 그림에서 보듯이
아주 부드럽게 transition이 일어나는 것을 확인할 수 있고 특정 물체가 사라지고 생기는 과정을 볼 수 있다.

#### 2) Visualizing the discriminator features

기존에 CNN내 feature의 역할을 알기 위해 진행되었던 연구 내용들을 바탕으로 discriminator의 feature들이
어떤 역할을 하는지 특정 물체들에 activate하는지 확인해보았다. <br>
![lsun4](https://whikwon.github.io/images/dcgan_lsun4.png) <br>
오른쪽은 guided backpropagation을 이용해서 시각화한 feature이고 왼쪽은 비교를 위해 random하게
initialize한 feature를 시각화하였다. 보다시피 침대, 창문 등 특정 물체에 크게 반응하는 각각의 feature가
존재한다는 것을 알 수 있다.

#### 3) Manipulating the generator representation

- Forgetting to draw certain objects
  discriminator의 feature가 학습한 내용을 위에서 확인했고 이제 generator는 어떻게 학습되었을지 확인해본다.
  확인 방법은 특정 물체에 active하는 generator의 feature를 없앴을 때의 결과를 보는 것이다.
  그림에서 아래 결과가 창문에 대한 feature를 drop하고 생성한 것으로 창문이 사라지고 다른 물체가 채운 것을 확인할
  수 있다.
  ![lsun5](https://whikwon.github.io/images/dcgan_lsun5.png)

- Vector arithmetic on face samples
  NLP 분야에서는 distributed representation을 통해서 단어들 사이의 의미를 좀 더 잘 나타낼 수 있는 방법을
  찾았다. (*i.g. 'King' - 'Man' + 'Woman' = 'Queen'*)마찬가지로 DCGAN으로 생성하는 이미지에서도 이런 것이 가능할지 확인해본다.
  방법은 latent space 내에서 vector 연산을 할 특정 물체를 나타내는 $$z$$ 값들을 뽑는다. 연산을 한 후에
  generator를 돌려서 연산이 제대로 이루어졌는 지 확인한다. (*이 때, 각각의 물체에 대해 여러 개 z를 뽑은 후에 평균을 냈을 때 잘 되었다고 한다.*)
  ![face1](https://whikwon.github.io/images/dcgan_face.png) <br>
  위 그림을 보면 모델이 이미지를 이해한 것처럼 결과가 잘 나온 것을 볼 수 있다. <br>
  다른 예시로는 아래 그림이 있는데 회전을 이해했는 지 확인하기 위해서 왼쪽을 보는 얼굴을 만드는 $$z_{left}$$의 평균과
  오른쪽을 보는 얼굴을 만드는 $$z_{right}$$의 평균을 계산해서 두 벡터을 잇는 축을 interpolation해서 generator에
  넣어준 결과이다. <br>
  ![face2](https://whikwon.github.io/images/dcgan_face2.png) <br>
  얼굴이 회전하는 것을 확인했고 모델이 이미지에서 **회전** 이라는 의미를 잘 이해했다고 볼 수 있다.

#### Conclusion

뛰어난 구조를 만들었으나 아직 모델의 instability 한 문제점이 남아있어 해결해야 하고 video, audio 등 다른
도메인에 적용되면 흥미로울 것이며 latent space에 대한 연구도 흥미로울 것이라고 얘기하고 마무리한다.


Alec Radford, Luke Metz, Soumith Chintala. [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434) <br>
[유재준님 블로그](http://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-2.html)
