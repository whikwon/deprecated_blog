---
title:  "ROC Curve"
date: 2017-11-13 00:00:00
layout: post
excerpt: 평가 방법 중 하나인 ROC Curve에 대한 내용이다.
categories: [Metrics]
comments: true
---

## ROC Curve 소개
정의가 어떻게 되는지 각 항들을 구성하는 요소는 무엇인지 먼저 살펴보자.
**ROC Curve** 는 FPR(False Positive Rate)를 x축으로 TPR(True Positive Rate)를 y축으로 했을 때 그린 곡선을 일컫는다.

FPR, TPR이 무엇인지 그리고 이를 일컫는 다른 명칭들이 어떤 것들이 있는지는 아래 [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)
를 보는 것이 이해가 빠를 듯하다. confusion matrix는 positive/negative로 구분된 데이터를 특정 모델로 평가했을 때 어떤 값으로 예측을 할 것이냐에 따라서 예측 값을
4가지로 구분해놓은 matrix이다.

[용어 정리]
1. True condition: 평가를 위해 가진 데이터의 참 값이다.  
  - Condition positive: 데이터가 positive하다.
  - Condition negative: 데이터가 negative하다.
2. Predicted condition: 모델로 평가했을 때의 데이터의 예상 값이다.
  - Predicted condition positive: 모델로 평가했을 때 데이터가 positive하다.
  - Predicted condition negative: 모델로 평가했을 때 데이터가 negative하다.

[confusion matrix 값]
- True Positive: Condition positive를 positive로 예측
- False Positive: Condition negative를 positive로 예측
- False Negative: Condition positive를 negative로 예측
- True Negative: Condition negative를 negative로 예측

![confusion matrix](https://whikwon.github.io/images/confusion_matrix.png)
<center> <i> &lt;Confusion matrix&gt;</i> </center> <br>

그럼 ROC Curve가 의미하는게 무엇인지 다시 살펴보자. 참고로, 아래 항들에서 분모는 변하지 않는다.    
- FPR: negative인데 positive로 잘못 예측한 개수 / 전체 negative 개수
  - 높으려면? : 전체를 positive라고 예측한다. 최대값 1
  - 낮으려면? : 전체를 negative라고 예측한다. 최소값 0
- TPR: positive인데 positive로 잘 예측한 개수 / 전체 positive 개수
  - 높으려면? : 전체를 positive라고 예측한다. 최대값 1
  - 낮으려면? : 전체를 negative라고 예측한다. 최소값 0

둘의 특성은 유사하다. FPR, TPR 모두 평가 데이터 전체를 positive로 예측한 경우 최대값(1)을 갖고 negative로 예측한 경우 최소값(0)을 갖는다.

이해를 돕기 위해 다음 두 가지 예시를 보자.
1. 감기 환자가 100명이 있는데 새로 개발한 감기약 종류 별 효과에 대한 평가 상황이다.
  - 0.1g부터 좋다: 조금만 투여해도 positive할 것이라고 예측할 수 있고 그게 맞다. FPR은 매우 낮은데 TPR은 매우 높게 된다. 더 투여하면
  모든 환자들이 다 나을 것이라고 예측한다. 모두 positive로 예측하게 되므로 FPR = TPR = 1이 된다.
  - 성능이 거의 없다: 조금 투여했을 때 negative할 것이라고 예측하고 그게 맞으므로 FPR = TPR = 0. 더 투여하면 그래도 환자들이
  나을 것이라고 예측한다. 많이 투여했을 경우 결국 모두 positive할 것으로 예측하게 될 것이므로 FPR = TPR = 1이 된다.
2. 환자 100명이 있는데 새로 개발한 종양 크기 진단 기기로 암 발병 유무를 판단하는 상황이다.
  - $$0.01mm^2$$부터 암이라고 판단한다: 모두 positive로 예측하게 되므로 FPR = TPR = 1이 된다.  
  - $$100m^2$$부터 암이라고 판단한다: 모두 negative로 예측하게 되므로 FPR = TPR = 0이 된다.

## ROC Curve의 필요성
첫번째 예시에서 우리가 알 수 있는 내용은 성능을 모르는 감기약들이 있을 때 감기약 별로 효과가 FPR, TPR에 나타난다는 점이다. <br>
자, 이제 위 예시를 추천 시스템에 빗대어서 생각해보자. 먼저, FPR, TPR의 값에 대해 생각해보자.
- 적게 추천한다: 대부분을 negative로 예측한다. FPR = TPR = 0
- 많이 추천한다: 대부분을 positive로 예측한다. FPR = TPR = 1

내용이 위 예시랑은 조금 반대다. 감기약의 경우에는 g수가 적을 때 효과적이면 성능이 좋은건데 추천 시스템은 개수가 많을 때 효과적이어야 성능이 좋은 것이다.
이를 기억하고 다시 써보자.
- 추천 성능이 좋다: 적게 추천했을 때에 다 맞고 수를 조금 늘려도 다 맞기 때문에 FPR보다 TPR이 가파르게 증가한다. 더 많이 추천하면 전부다 positive로 추천
하게 되므로 FPR = TPR = 1에 도달한다.
- 추천 성능이 좋지 않다: 적게 추천했을 때는 그래도 좀 맞지만 수를 조금 늘리면 틀리기 시작한다. 그러므로 FPR와 TPR이 비슷하게 증가한다. 더 많이 추천하면
전부다 positive로 추천하게 되므로 FPR = TPR = 1에 도달한다.

위 내용처럼 첫번째 예시를 통해 우리가 학습시킨 추천 시스템들의 성능을 ROC Curve를 통해 비교했고 아래 그래프에서 처럼 추천 개수에 따른 모델 별 ROC Curve들을 비교했을 때
좀 더 위 쪽에 위치하는 좋은 성능의 모델을 얻었다고 하자.

![ROC Curve2](https://whikwon.github.io/images/rec_roc_curve2.png)
<center> <i> &lt;추천 개수에 대한 모델 별 ROC Curve&gt;</i> </center> <br>

이제 모델은 얻었는데 고객에게 추천할 때 평점 몇을 기준으로 추천을 해 줄지 고민이다.

이에 대한 답은 두번째 예시를 통해 알 수 있다. 위 예시와 같이 0.1점이나 4.9점을 기준으로 추천을 해서는 당연히 좋은 결과를 얻기 힘들며 적정한
점수를 기준으로 추천을 해야 한다. 이 적정한 값은 ***cutoff*** 이라고 하며 구하는 알고리즘이 다양하게 있지만 이 부분은 다음에 소개하도록 하겠다.

아래는 item의 관련성에 대한 density function을 나타낸 그래프와 추천 평점에 대해서 그린 ROC Curve이다.

![density functions for relevant and irrelevant items](https://whikwon.github.io/images/rec_density_function_for_item.png)
<center> <i> &lt;item의 관련성에 대한 density function&gt;</i> </center> <br>

![ROC Curve](https://whikwon.github.io/images/rec_roc_curve.png)
<center> <i> &lt;평점 기준에 대한 ROC Curve&gt;</i> </center> <br>

## 정리
ROC Curve를 통해서 추천 시스템의 성능을 비교할 수 있고 실제 고객에게 서비스를 할 때 현재 모델의 성능으로 $$n$$ 개의 추천을 제시했을 때
얼마나 틀리거나 맞을 지에 대한 예측을 가능하게 해준다.

Reference: <br>
[Wikipedia - Receiver operating characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) <br>
[JONATHAN L. HERLOCKER. Evaluating Collaborative Filtering Recommender Systems. 2004](https://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf) <br>
[Andrew I. Schein. Methods and Metrics for Cold-Start Recommendations. 2002](http://repository.upenn.edu/cgi/viewcontent.cgi?article=1141&context=cis_papers)
