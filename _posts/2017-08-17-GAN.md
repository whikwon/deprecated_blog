---
title:  "GAN"
date: 2017-08-21 00:00:00
layout: post
excerpt: "2014년에 Ian Goodfellow가 발표한 Generative model인 GAN(Generative Adversarial Nets) 논문이다."
categories: [GAN, Generative model, Paper]
comments: true
---

## 1. Introduction <br>
딥러닝의 여러 분야에서 이뤄낸 성과들을 소개하면서 Deep *generative* model의 경우 approximation of intractable probabilistic
computation에서의 어려움을 겪어 크게 발전하지 못하고 있다고 애기하고 있다.

이에 다른 방식으로 접근한 GAN이라는 새로운 모델을 소개하는데, GAN은 단순한 multilayer perceptron으로만 이루어져 있어
Generative 모델이 어려움을 겪는 **approximation inference, Markov chain이 존재하지 않는다.**

GAN이 학습하는 방법은 아주 쉽게 풀어서 설명하고 있다. <br>
*경찰(Discriminator)과 화폐위조범(Generator)가 있다. 경찰은 위조화폐($$1-D(G(z))$$)와 진짜화폐($$D(x)$$)를 정확하게 감별해야 하고,
화폐위조범은 경찰을 속여야한다.($$D(G(z))$$) 계속해서 이러한 전략으로 학습할 때 경찰은 더 잘 구분하고 화폐위조범은 더 그럴싸한
위조화폐를 만들어낼 것이다. 그리고 충분히 잘 학습했을 때 위조화폐를 진짜화폐와 구분할 수 없을 정도로 생성해낼 것이라는게 GAN의 핵심이다.*

## 2. Adversarial Nets <br>

> Notation부터 정리하고 살펴보도록 하겠다. <br>
$$ p_z(z) : noise\ 변수의\ prior분포(Gaussian),\ p_g : generator의\ x에\ 대한\ 분포$$ <br>
$$x: 실제\ data,\ D(x; \theta_d) : multilayer\ perceptron(discriminator)\ with\ parameter\ \theta_d $$<br>
$$ G(z; \theta_g) : multilayer\ perceptron(generator)\ with\ parameter\ \theta_g$$

위에서 설명한 내용처럼 GAN의 문제는 결국 $$D$$가 $$1-D(G(z)),\ D(x)$$를 maximize하게 학습시키고, $$G$$가 $$1-D(G(z))$$를 minimize하게
학습시키는 minimax 문제로 볼 수 있고 아래와 같은 식으로 나타낼 수 있게 된다. <br>
$$\begin{align} \underset {G} {\rm min} \underset D {\rm max} V(D,G) = \mathbb{E}_{x \sim p_{data(x)}} [logD(x)] + \mathbb{E}_{z \sim p_z(z)} [log(1-D(G(z)))] \end{align}$$
식을 정의했으니 이제 위 식을 통해서 $$G$$와 $$D$$가 충분한 capacity와 시간이 주어졌을 때 이론적으로 학습이 가능한지 수렴하는지에 대해 뒷 장에서 볼 예정이다.

위 식에서 한가지 덧붙이자면 실제 $$G$$학습 시에 위 식으로 할 경우 saturation이 발생하여 $$1- D(G(z))$$를 minimize하는 문제에서
$$D(G(z))$$를 maximize하는 문제로 바꿔서 Objective function을 정의한다고 한다. (*saturation 내용 tutorial 참고.*)

## 3. Theoretical Results <br>

$$G$$와 $$D$$가 충분한 capacity와 시간을 주어졌을 때 좋은 estimator로 수렴 가능한지 증명할 예정이다. 순서는 먼저 GAN의 minimax식이 $$p_g = p_{data}$$을
global optimum으로 갖는다는 것을 보인 후에 $$(1)$$식을 optimize한다는 것을 보이는 순으로 진행한다.

![Figure1](https://whikwon.github.io/images/gan_figure1.PNG)
학습에 따른 $$p_{data},\ p_g$$의 변화를 잘 나타낸 논문 내 설명 그림이다. 보면서 어떤 식으로 변화할 지에 대한 직관을 얻도록 하자.
파란점선이 discriminator distribution, 검은점선이 data generating distribution($$p_{data}$$)을, 초록실선이 generative distribution($$p_g$$)을 나타낸다.
그 아래 선들은 x와 z의 domain을 각각 나타낸다. (noise랑 실제 data) 화살표는 $$x=G(z)$$ mapping을 나타낸다.
학습 진행 시 모델의 변화를 보면 (a)에서는 discriminator가 어느 정도 classifier로써의 역할을 하고 초록선과 검은선은 매우 떨어져 있어
$$p_g$$가 $$p_{data}$$로부터 많이 떨어져있다는 것을 확인할 수 있다. 학습을 더 시키면 (b)의 상태가 되고 discriminator의 성능이
좀 더 좋아진 것을 확인할 수 있다. 추가 학습 시 (c)를 거치면서 $$p_g$$가 $$p_{data}$$로 가까워지고 그에 따라 discriminator가 둘을 구별하지
못하면서 $$p_g = p_{data}, D(x) = {1\above 0.5pt 2}$$로 수렴하게 된다는 설명이다.

그럼 본격적으로 증명을 해보도록 하자.

### 3.1 Global Optimality of $$p_g = p_{data}$$ <br>

증명을 위해 **proposition 1** 을 먼저 보고 **Theorem 1** 을 살펴보도록 하겠다. <br>

**Proposition 1.** <br>
> *For $$G$$ fixed, the optimal discriminator D is <br>*
$$D_G^*(x) = {p_{data}(x) \above 0.5pt {p_{data}(x) + p_g(x)}}$$ <br>
*Proof.* The training criterion for the discriminator $$D$$, given any generator $$G$$, is to maximize the
quantity $$V(G,D)$$ <br>
$$\begin{align}V(G,D) &= \int_x p_{data}~(x)log(D(x))dx + \int_z p_z(z)log(1-D(G(z)))dz \\
&= \int_x p_{data}~(x)log(D(x)) + p_g(x)log(1-D(x))dx \end{align}$$ <br>
어떤 $$(a,b) \in \mathbb{R}^2 \backslash \{0,0\}$$에 대해서 함수 $$y \rightarrow a\log(y) + b\log(1-y)$$는 최대값을 $$[0,1]$$에서 $$a \above 0.5pt {a+b}$$로 갖는다.
$$Supp(p_{data}) \cup Supp(p_g)$$ 범위 밖에서 discriminator를 정의할 필요는 없다. (*정확한 내용 이해 필요*)<br>
proposition1은 $$G$$가 고정되어 있다고 가정했을 때 optimal discriminator를 찾는 과정이다. 위 1번 식은
앞의 minimax 함수를 풀어놓은 것이며 위 proof에서 얘기하는 전제에 따라 2번 식으로 유도가 가능해지며
$$D_G^*(x) = {p_{data}(x) \above 0.5pt {p_{data}(x) + p_g(x)}}$$ 일 때 최대값을 갖게 된다. <br>
그럼, 이제 앞서 $$G$$를 고정시킨 상태의 minimax 함수를 $$C(G)$$로 다시 정의하면 아래처럼 reformulate 된다. <br>
$$\begin{align} C(G) & = \max_D V(G,D) \\
&= \mathbb{E}_{x \sim p_{data}} \left[ log D^*_G(x) \right] + \mathbb{E}_{z\sim p_z}\left[ log(1-D^*_G(G(z))) \right] \\
&= \mathbb{E}_{x \sim p_{data}} \left[ log D^*_G(x) \right] + \mathbb{E}_{x\sim p_g}\left[ log(1-D^*_G(x)) \right] \\
&= \mathbb{E}_{x \sim p_{data}} \left[ log \frac{p_{data}~(x)}{p_{data}~(x)+p_{g}(x)} \right] + \mathbb{E}_{x\sim p_g} \left[ log \frac{p_{g}(x)}{p_{data}~(x)+p_{g}(x)} \right] \end{align}$$ <br>
위 식을 바탕으로 theorem을 증명해보도록 하자.

**Theorem 1.** <br>
> *The global minimum of the virtual training criterion $$C(G)$$ is achieved if and only if
$$p_g = p_{data}$$. At that point, $$C(G)$$ achieves the value - $$log 4$$.* <br>
*Proof.* $$p_g = p_data$$일 때 $$D_G^*(x) = {1 \above 0.5pt 2}$$를 만족하며(Eq.2 참조),
$$D_G^*(x) = {1 \above 0.5pt 2}$$ 일 때 Eq.4를 보면 $$C(G) = -log4$$이다. 그럼 이 값이 최적이라는 것을 알기 위해 위의
$$C(G)$$ 식을 적절히 변형시켜야 하는데 이때 $$KL, JSD$$가 사용된다. <br>
$$\begin{align}C(G) &= -log(4) + KL \left( p_{data} || \frac{p_{data}~+ p_g}{2}\right) + KL \left( p_g|| \frac{p_{data}~+ p_g}{2}\right) \\
&= -log(4) + 2\cdot JSD(p_{data}||p_g) \end{align}$$ <br>
여기서 JSD는 항상 양수이므로 $$C^*=-log(4)$$가 global minimum이며 이 때 유일한 해가 $$p_g=p_{data}$$라는 것을 알 수 있다.
즉, global optimal을 찾으면 $$p_g = p_{data}$$을 일치시킬 수 있고 data와 완전히 동일한 샘플을 만들어낼 수 있다는 것을 보았다. <br>
(하지만 **global optimal**을 어떻게 찾을 것이냐는 또 다른 문제이다.)

### 3.2 Convergence of Algorithm 1 <br>

이제 논문에서 사용한 MLP 모델의 G, D가 Global optimal로 수렴하는 지 볼 예정이다.

**Proposition 2.** <br>
>*If $$G$$ and $$D$$ have enough capacity, and at each step of Algorithm 1, the discriminator
is allowed to reach its optimum given $$G$$ and $$p_g$$ is updated so as to improve the criterion <br>
$$\mathbb{E}_{x \sim p_{data}} \left[ log D^*_G(x) \right] + \mathbb{E}_{x\sim p_g}\left[ log(1-D^*_G(x)) \right]$$
then $$p_g$$ converges to $$p_{data}$$.* <br>
*Proof.* $$V(G,D) = U(p_g, D)$$ 라고 $$U(p_g,D)$$ 함수를 정의하고 이 함수는 $$p_g$$에 대해 convex한 성질이 있다.
convex함수의 supremum(상한)에 대한 subderivative는  maximum에 대한 derivative도 당연히 포함할 것이다. <br>
이를 수식으로 나타내면 $$f(x) = sup_{\alpha \in A}f_{\alpha}(x)$$ $$f_{\alpha}(x)$$이고 $$x$$에 모든 $$\alpha$$에 대해 convex하면,
 $$\beta = argsup_{\alpha \in A}f_{\alpha}(x)$$ 일 경우 $$\partial f_{\beta}(x) \in \partial f$$ 하다.
 라고 나타낼 수 있다.
이 내용은 결국 $$p_g$$에 대해 gradient descent update를 해서 $$G$$를 주어졌을 때 optimal $$D$$을 찾는 것과 같다.
$$sup_D U(p_g,D)$$가 $$p_g$$에 convex하고 Thm1에서 보인 것처럼 unique global optima를 가지므로
$$p_g$$를 충분히 update하면 $$p_x$$에 수렴할 수 있을 것이라고 한다.
그리고 모델들이 극점을 많이 가지므로 정확하게 global optima로 수렴하진 않을 것이며
$$p_g$$ 분포를 optimize할 때 $$G(z;\theta_g)$$에서 $$\theta_g$$를 optimize하므로 증명이 완전히 적용되진 않는다고 한다. <br>
그래도 실용적으로 사용하기에는 reasonable하다고 말미에 덧붙이고 있다.

추가 설명. 위 증명에서 $$U(p_g,D)$$가 $$p_g$$에 대해 convex라고 하였는데 이는 $$V(G,D)$$(Eq.3)
(*convex하다는 의미는 $$U(a*p + (1-a)*q, D) <= aU(p,D) + (1-a)U(q,D)$$ 를 나타낸다.*)
을 보면  $$p_g(x)$$가 존재하고 해당 변수에 대해서 convex를 만족하는 지 식을 정리해보면(위 식)
만족한다는 것을 확인할 수 있다. (이해가 안 되면 [여기](https://www.overleaf.com/5220526hxjpzg#/16376044/)를 보자)


Reference:  <br>
1. Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. ["Generative Adversarial Networks"](https://arxiv.org/pdf/1406.2661.pdf). 2014.
2. [유재준씨 블로그](http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html)
