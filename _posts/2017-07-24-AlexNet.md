---
title:  "AlexNet"
date: 2017-07-18 00:00:00
comments: true
---

- Univ. of Toronto에서 2012년도에 발표한 ILSVRC-2012에서 1등을 차지한 모델이다.

#### 1. Introduction <br>
Object recognition에 더 큰 dataset에 대한 학습을 진행하기 위해서는 capacity가 큰 모델이 필요해졌고
standard NN에 비해 비교적 적은 connection과 parameter, 쉬운 training, image의 특성(locality of pixel dependency) 등을 고려하여
CNN을 선정하게 된다. <br>
그리고 큰 dataset을 학습하는 데 필요한 연산은 GPU로 해결하였으며 overfitting을 막기 위해 여러가지 technique를 사용하였다.
나머지 상세한 내용은 뒤에서 설명하도록 하겠다.

#### 2. Dataset <br>
학습을 위해 ImageNet에 있는 dataset에서 대략 1000개의 categories에 맞는 1000개 images를 사용했다.
총 1.2백만개의 training images, 5만개의 validation images, 15만개의 testing image가 학습에 사용되었다.
다양한 크기의 image를 256X256 크기로 만들었고 training set의 pixel값 mean subtract만 전처리에 사용하였다.

#### 3. The architecture <br>
아래 그림은 AlexNet의 구조를 나타낸다. 총 8개의 layer로 이루어져 있으며 5개의 convolutional, 3개의 fully-connected로 구성된다. <br><br>
![Figure2](https://chaosmail.github.io/images/deep-learning/alexnet.png)

  - **ReLu Nonlinearity** <br>
  activation function을 saturating 특성이 없는 ReLu로 변경하였고 아래 그림에서 볼 수 있듯이
  tanh 대비 약 6배 정도 학습 속도가 빨라졌음을 확인할 수 있다.
  ![Figure1](http://images.cnitblog.com/blog2015/678029/201504/280120355838911.png) <br><br>

  - **Training on Multiple GPUs** <br>
  GTX580 3GB GPU를 2개 사용하였고 layer를 위, 아래로 쪼개어 각각 GPU가 나누어 처리할 수 있도록 하였다.

  - **Local Response Normalization** <br>
  ReLu를 activation function으로 사용했을 때의 장점 중에 하나가 saturating 걱정이 없어 input normalization의 필요가 없어진다는
  점이다.(batch normalization과 연결되는 개념) 그럼에도 불구하고 generalization을 추가하여 성능 향상을 이뤘다고 얘기하고 있다.
  이 후 발표되는 모델에서 빠지는 개념으로 상세하게 다루지는 않도록 하겠다.

  - **Overlapping Pooling** <br>
  Overlapping pooling이 overfitting에 빠지지 않는다고 하여 사용했다.

  - **Overall Architecture** <br><br>
  ![Alexnet_structure](https://whikwon.github.io/images/alexnet.PNG) <br><br>
  각각 layer들의 위치, GPU간 communicate하는 layer 등 상세한 구조가 위 그림에서 자세하게 나타나 있다. 참조하면서 보면 쉽게 이해가 된다.

#### 4. Reducing Overfitting
parameter가 많다보니 overfitting이 일어나서 어떻게 해결했는 지에 대해 아래에서 소개하겠다.
  - **Data Augmentation** <br>
  문자 그대로 데이터를 늘리는 방법이다.
  참고로 GPU가 이전 이미지를 학습할 동안에 CPU내 python code에서 데이터가 생성되고 disk엔 저장될 필요도 없어서 연산량이 크게 늘지 않는다고 한다. <br>
  Augmentation 방법은 training 시에 두가지 방법을 채택하여 사용했다. 첫번째로 training시에 256X256 크기의 이미지에서 224X224 크기의 patch를 random하게 추출, 수평 반전시켜
  총 2048개의 이미지를 얻었다. <br>
  두번째로 얻은 이미지의 RGB 채널의 값을 변화시켜주었다. RGB 픽셀에 대한 PCA를 수행한 후에 평균 0, 표준편차 0.1을 갖는
  랜덤 변수를 곱해서 원래 픽셀 값에 더해주는 방식으로 컬러 채널의 값을 변경시켰고 다양한 training 이미지를 얻게 되었다. <br>
  식으로 표현하면 아래와 같다.
  $$I_{xy} = [I^R_{xy}, I^R_{xy}, I^B_{xy}]^T + [p_1,p_2,p_3][\alpha_1\lambda_1, \alpha_2\lambda_2,\alpha_3\lambda_3]^T$$ <br>
  $$\alpha \sim \mathcal{N}(0,0.1)$$ <br>
  참고로 두번째 방법을 사용해서 top-1 에러율을 1% 이상 줄였다고 한다.
  최종적으로 test시에는 256X256 크기의 이미지에서 224X224 크기의 patch를 5개(corners, center) 추출하고 수평 반전시켜 10개의 softmax 평균을 내어
  모델의 성능을 계산하였다.

  - **Dropout** <br>.
  $$p=0.5$$인 dropout을 첫번째, 두번째 FC layer에 적용하였다. dropout으로 overfitting을 없앴으며 converge하기 위한 iteration 수를 대략 2배로 증가시켜 진행했다.

#### 5. Details of learning
더 상세한 조건의 경우 CS231n 강의 슬라이드를 참조하도록 하겠다. <br><br>
  ![Alexnet_structure](https://whikwon.github.io/images/alexnet_2.PNG) <br><br>

#### 6. Result
top-1, top-5에서 각각 37.5%, 17.0% 에러율을 기록하면서 1등을 차지했다. <br>
결과가 어땠는지 살펴보도록 하자. <br>
![figure3](http://benkampha.us/img/alex-net-intermediate.png) <br><br>
위 그림은 첫번째 convolutional layer로 GPU를 2개로 나누어 위/아래 학습한 결과이다. 아래 쪽 GPU의 kernel이
color-specifci한 것을 확인할 수 있다. <br>
![figure4](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/2315fc6c2c0c4abd2443e26a26e7bb86df8e24cc/7-Figure4-1.png) <br><br>
위 그림은 Test image의 일부 결과이다. <br>

#### 7. Discussion
AlexNet의 결과 중 가장 중요한 점은 depth와 연산량을 늘려 좋은 결과를 이뤘다는 점이다.
Depth의 중요성에 대해선 앞으로 소개할 VGGNet, GoogleNet, ResNet에서도 공통적으로 나타날 예정이다.

Reference: <br>
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. ["Imagenet classification with deep convolutional neural networks."](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) Advances in neural information processing systems. 2012
Stanford Univ. [CS231n lecture 9 21th slide](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf). 2017
