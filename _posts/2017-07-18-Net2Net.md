---
title:  "Net2Net"
comments: true
---
- 2016년에 ICLR에 발표된 논문이다.

#### 1. Introduction <br> <br>
소개하는 내용은 간단하다. 간단한, 토대가 되는 teacher neural network를 학습한 결과를
바탕으로(function-preserving) 이를 어떻게 좀 더 wider, deep한 student neural network를 어떻게 학습할 수 있을 지에 대한
내용을 소개하고 있다. <br>
2가지 transformation에 대해 소개하고 있으며 Net2WiderNet과 Net2DeeperNet이다. <br>
Net2Net이라는 모델이 나온 배경은 현재 Machine learning 모델 학습 방법의 문제에 있다. <br>
현재 모델들은 주로 다음과 같이 학습된다. <br>
먼저, 간단한 구조의 모델을 만든다. 그리고 모델을 계속 사용하다 일정 기간이 지나면 더 많은 데이터를 바탕으로 처음부터
다시 학습 시켜 성능을 향상시킨다. 마지막으로 이런 과정을 주기적으로 반복한다. <br>
이런 방식의 문제점은 데이터가 지속적으로 많아지고 모델의 capacity도 계속 증가할 것이므로 학습 시간이 점점 길어지는 데에 있다. <br>
위의 문제를 해당 논문에서 Net2Net 방식으로 기존 모델을 바탕으로한 새로운 모델을 어떻게 빠르게 학습할 수 있는 지에 대한 내용을 다루고 있다. <br>
아래 그림은 현재 training 방식 및 Net2Net 방식을 도식화 해놓은 것이다. <br> <br>
![Figure1](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/16cb6876666f3a7b56a636c1d85ad00bd0d98bf3/1-Figure1-1.png)

#### 2. Methodology <br> <br>
- feature prediction <br>
Net2Net의 방식은 이전에 발표된 FitNets의 접근법과 매우 유사한데 Batch Normalization 사용했을 때 성능 향상 효과가 떨어져서
약간 다른 방식으로 접근했다고 얘기한다.(참조)

- function-preserving initializations <br>
function-preserving initialization의 장점들에 대해서 소개하고 있다.
  1. larger network이 initialization 직후 original에 버금가는 성능을 보이며 이 후 학습은 improvement로 이어진다.
  2. Network 내 모든 parameter들을 optimize하기에 safe한 방법이다. (이해 안 됨.)

- Net2WiderNet <br>
이름에서도 알 수 있듯이 Network를 좀 더 Wider하게 만들어주는 방법이다.
Convolution의 경우 channel수가 증가한다고 보면 된다.
아래 그림에 잘 설명되어 있다. layer를 증가시키 위해서 unit을 추가하고, 그만큼 기존 unit들에서 수행되던 연산을
새로운 unit에 분산해서 output이 기존과 동일하게 나오도록 해준다. <br> <br>
![Figure2](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/16cb6876666f3a7b56a636c1d85ad00bd0d98bf3/3-Figure2-1.png) <br> <br>
위와 같은 구조를 만들어줄 때 유념해야할 점이 있다. 위 그림에서는 single random mapping function에 대해서만 고려하고 있는데
실제 학습시킬 때에는 batch normalization와 같은 다른 random remapping function이 연산에 추가될 수 있다.
그래서 추가되었을 때 function preserve한지 확인해보았다.
주로 사용되는 batch normalization, concatenation의 총 2가지 function을 살펴보았고 모두 단순히 Wider시켰을 때
기존과 output이 달라지는 것을 확인할 수 있었다.
이러한 점을 해결하기 위해 remapping inference algorithm이 필요하고 일단 해당 논문에선 Inception network에 대해서
algorithm 구현 및 사용하였다고 한다.
추가로, dropout과 같은 randomization을 사용하지 않았을 경우에는 ***first copy of each column of weights*** 를 제외하고
noise를 추가해주어야 teacher에 approximate하게 student가 표현하고 이 후 추가적인 학습할 때 모든 capacity를 발휘할 수 있다고 한다.


- Net2DeeperNet <br>
다음으로 설명할 모델도 마찬가지로 이름에서 나타나듯이 Network를 좀 더 Deep하게 만들어주는 방법이다.
아래 그림과 같이 output layer전에 identity matrix를 더해주어 기존 output과 동일하게 출력하면서 Deep하게 만든다.
근데 activation function 종류에 따라 여러가지 제약 사항이 생긴다. convolution의 경우는 identity filter를 추가하면 되겠다. <br>
![Figure3](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/16cb6876666f3a7b56a636c1d85ad00bd0d98bf3/4-Figure3-1.png) <br> <br>
추가적으로 general factorization of layers에 대한 중요성을 강조하고 있고 DeeperNet의 경우는 noise를 추가하지 않아도
학습에 문제가 없다고 한다.

#### 3. Experiments <br> <br>
모든 경우에 Inception-BN network, ImageNet의 데이터를 사용했다.
비교군은 Net2WiderNet의 경우 Random Pad(random한 값을 가지는 새 unit 추가)를 Net2DeeperNet의 경우
Random initialization로 채택하였다.

- Net2WiderNet <br>
실험 결과는 아래와 같다. Net2WiderNet을 사용한 경우 사용하지 않을 때보다 converge하는 속도가 빠른 것을 확인하였다.
training을 충분히 진행했을 때 converge하는 accuracy는 거의 동일하다. <br>
![Figure4](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/16cb6876666f3a7b56a636c1d85ad00bd0d98bf3/6-Figure4-1.png) <br> <br>

- Net2DeeperNet <br>
실험 결과는 아래와 같다. Net2DeeperNet을 사용한 경우 사용하지 않았을 때보다 converge하는 속도가 빠른 것을 확인하였다.
또한, teacher network와 비교했을 때 성능이 향상되었다. <br>
![Figure5](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/16cb6876666f3a7b56a636c1d85ad00bd0d98bf3/7-Figure5-1.png) <br> <br>

#### 4. Discussion <br> <br>
Net2Net로 구조적인 제약조건 아래에서 small neuural network에서 large neural network로 transfer learning 할 수 있다는 것을 보였다.
아래는 ImageNet 데이터로 진행한 추가적인 실험이다. <br>
![Figure6](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/16cb6876666f3a7b56a636c1d85ad00bd0d98bf3/8-Figure6-1.png) <br> <br>


Reference: <br>
Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. ["Net2net: Accelerating learning via knowledge transfer."](https://arxiv.org/abs/1511.05641) arXiv preprint arXiv:1511.05641 (2015).
