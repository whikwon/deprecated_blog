---
title:  "VGGNet"
date: 2017-07-24 00:00:00
comments: true
---

- ILSVRC-2014에서 localization 1등, classification 2등한 모델이다. (1등은 GoogleNet) <br>
- 망이 깊어졌을 때의 성능의 향상 여부에 초점을 맞춘 모델이다. 구조가 매우 단순하다.

***
### 1. Introduction<br>
논문에서 주로 ConvNet의 구조 중 depth에 대해서 다룰 것이라고 소개한다.

***
### 2. ConvNet configurations<br>
  - **Architecture**<br>
  224X224 RGB 이미지를 input으로 받고, training시 전처리는 subtracting mean만 해준다.
  filter의 구조는 3X3과 1X1만 사용하고 stride도 전부다 1로 spatial resolution이 보존되게 하였다.
  spatial pooling의 경우는 max-pooling 때 되도록 하였으며 2X2 pixel window에 stride 2를 사용하였다.
  convolutional layer 뒤에 FC layer가 3개 존재하고 앞서 봤던 모델의 구조와 같다.
  앞의 2개 layer는 4096개 channel을 갖고 마지막 layer에서 softmax 진행되며 class의 개수인 1000개 channel만 남는다.
  앞서 AlexNet에서 사용했던 Local Response Normalization은 실험 후 성능에 효과가 없다고 판단되어 사용하지 않는다.

  - **Configurations**<br>
  아래 그림의 table1에 논문에서 비교하려는 모델들의 구조가 나타나있다. 전체적인 기본 디자인은 전부다 같으며 depth의 차이가 난다.
  table2에서는 parameter수가 모델 별로 나타나 있는데 가장 기본이 되는 11-layer 구조와 19-layer의 parameter수가
  별 차이가 나지 않는 것을 볼 수 있는데 이는 parameter의 경우 FC layer에 어차피 거의 집중되어 있어서 그런듯하다. <br><br>
  ![table1,2](http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/img/vggModel.jpg)

  - **Discussion**<br>
  AlexNet에서 11X11, stride 4, ZFNet에서 7X7, stride 2를 첫번째 layer에서 사용한 것과 달리 VGGNet에서는
  3X3 receptive field만 사용하며 3X3의 반복을 통해 5X5, 7X7의 동일한 효과를 낼 수 있다고 말한다.
  그럼 이렇게 했을 때 이점이 있을까? 그렇다.
  첫번째로 ReLu layer가 추가되면서 non-linearity가 증가하고 decision function을 discriminative하게 만든다고 한다.
  두번째는 parameter수가 줄어든다.
  마찬가지의 이유로 1X1 layer도 사용되는데 receptive field에 영향을 주지 않으면서 non-linearity를 증가시킬 수 있다.
  GoogleNet과 마찬가지로 [Network in Network - Lin et al.](https://arxiv.org/pdf/1312.4400.pdf)에서 사용한 것을 보고
  영향을 받았다고 한다.

***
### 3. Classification framework<br>
  - **Training**<br>
  training 방법은 AlexNet이랑 거의 유사하게 진행되었으며 batch size 256, momentum 0.9, dropout 0.5,
  weight decay, learning rate 0.01(val set accuracy 증가 멈추면 10씩 감소) 등의 조건으로 수행했다.
  training은 총 74 epoch 동안 진행되었고 이는 AlexNet보다 더 적게 소요된 것이라고 한다. 이렇게 적은 epoch에도
  training 할 수 있었던 이유는 깊은 망, 작은 conv filter에 의한 implicit regularization 효과와 pre-initialization 때문이라고 한다.
  깊은 망일수록 initialization이 중요한데 VGGNet에서는 pre-training으로 해결하였다. 11-layer 모델을 먼저 random initialization(mean 0, variance 0.01)
  하여 충분히 학습시킨 후에 이를 다른 모델을 학습시킬 때 활용하엿다.

  - **Training image size**<br>
  이미지 augmentation을 위한 crop size는 224X224로 정해져있으며(input size) crop하는 대상은 원본의 rescaled된 이미지이다.
  여기서 rescaled할 때 어떤 크기로 하느냐가 매우 중요한데, 크게하면 crop했을 때 부분만 표현되게 할 수 있고, 작게하면 전체 이미지가
  전부 표현되게 되기 때문이다. VGGNet에서는 두가지 방법을 택해서 사용하고 있다.
  첫번째는 scale을 254, 384 두가지로 고정하여 사용하는 방법이고 두번째는 [256, 512] 크기 사이에서 random sampling해서 가져오는 방법이다.
  training 속도 문제를 해결하기 위해 두 방법 모두 pre-training을 진행하였다.

  - **Testing**<br>
  두가지 방법을 함께 사용했다. Overfeat 모델에서 소개된 dense evaluation 방법과 GoogleNet에서 사용된 Multi-cropping 방법을 함께 사용하였다.
  Multi-cropping의 ConvNet을 지날 때 feature map이 zero padding 되는 점이 전체적인 receptive field가 다양한 context를 capture할 수 있게
  해준다고 한다. (dense evaluation은 padding이 주변 이미지가 와서 안 된다고.. 제대로 이해한게 맞는지 모르겠다.)

***
### 4. Classfication experiments<br>
 - **Single scale evaluation**<br>
 test 이미지를 single scale로놓고 크게 train, test에 사용할 이미지의 크기($$S, Q$$)와 depth를 중점적으로 변화시키며
 성능을 확인하였다. 또한, LRN 사용유무에 따른 성능 평가도 진행하였다.
 평가 결과는 아래와 같다. 먼저, LRN의 사용유무에 따라 성능에 차이가 없음이 확인되어 더이상 사용하지 않는다.

    - A, A-LRN 비교 시 성능 차이가 없음을 확인.
    - B가 A보다 성능이 좋음.(3X3 2layer 차이) depth가 깊어짐에 따라 성능이 좋아짐을 확인.
    - C가 B보다 성능이 좋음.(1X1 3layer 차이) non-linearity가 성능에 영향을 준다는 점을 확인.
    - D가 C보다 성능이 좋음.(1X1 대신 3X3 사용) conv filter로 spatial context capture 하는게 중요하다는 점 확인.
    - training시 scale jittering $$(S \in [256;512])$$ 했을 때 fixed scale로 했을 때$$(S=256\ or\ S=384)$$보다 성능이 좋게 나왔으며 multi-scale image statistics를 capture하는데 도움을 줬을 것으로 생각된다.<br><br>
    ![Table3](http://mblogthumb2.phinf.naver.net/20160630_289/laonple_1467259172054sspYy_PNG/%C0%CC%B9%CC%C1%F6_43.png?type=w2)

 - **Multi-scale evaluation**<br>
 앞서 training시 scale jittering 효과에 대해 살펴보았고, test시에도 multi-scale로 적용해서 성능이 향상되는 지 살펴본다. 마찬가지로
 성능이 향상된 것을 확인할 수 있다. 평가 결과는 아래 표에 나타나있다.<br><br>
 ![Table4](http://mblogthumb2.phinf.naver.net/20160630_161/laonple_1467259323970DuKM3_PNG/%C0%CC%B9%CC%C1%F6_46.png?type=w2)

 - **Multi-crop evaluation**<br>
 마지막으로 dense evaluation, multi-crop evaluation 방법 비교를 한다.
 단일 평가 시에는 multi-crop이 성능이 좋게 나왔고, 같이 사용했을 때 좀 더 성능이 향상됨을 확인했다.
 convolution boundary condition이 두 평가 방법이 달라서 서로 보완하는 것 같다고 얘기하고 있다.
 평가 결과는 아래 표에 나타나있다.<br><br>
 ![Table5](http://mblogthumb1.phinf.naver.net/20160630_120/laonple_14672591723355hgpI_PNG/%C0%CC%B9%CC%C1%F6_45.png?type=w2)

 - **Comparision with the state of the art**<br>
 최종적으로 ensemble을 하여 top-5 test 기준 6.8%까지 성능을 향상시켰다.

***
### 5. Conclusion<br>
지금까지 VGGNet에 대해 살펴보았다. 해당 모델에서 가장 중요한 점은 기존 모델들에서 생각했던 것과 마찬가지로
깊은 depth가 image classification의 성능을 크게 향상시킬 수 있다는 점이다.



Reference: <br>
 Simonyan, Karen, and Andrew Zisserman. ["Very deep convolutional networks for large-scale image recognition."](https://arxiv.org/pdf/1409.1556.pdf) arXiv preprint arXiv:1409.1556 (2014)
